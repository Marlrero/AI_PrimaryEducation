{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hlzAA7jy7-4wj-8W4Dn30TOQ9RXlLpf1",
      "authorship_tag": "ABX9TyPcjh/tHu0fueXFWzi0fcuz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marlrero/AI_PrimaryEducation/blob/main/speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wWQe85ug49I"
      },
      "source": [
        "### Keras CNN과 RNN(GRU)으로 음성 인식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBX9x14fg_at"
      },
      "source": [
        "#### 1. import packages & set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAr_CVB9g3O-"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import random\r\n",
        "from time import time\r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.utils.np_utils import to_categorical # One-hot encoding\r\n",
        "from keras.layers import BatchNormalization, Bidirectional, Conv1D, Dense, \\\r\n",
        "                         Dropout, GRU, Input, MaxPooling1D\r\n",
        "from keras.models import Model\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "import librosa\r\n",
        "import librosa.display"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM5xEGOaixs-"
      },
      "source": [
        "# hyperparameters\r\n",
        "MY_SPLIT = 0.8\r\n",
        "MY_HIDDEN = 128\r\n",
        "MY_DROP = 0.3    # dropout\r\n",
        "MY_BATCH = 128\r\n",
        "MY_EPOCH = 100\r\n",
        "MY_PATH = '/content/drive/MyDrive/dataset/audio'\r\n",
        "\r\n",
        "# mode selection\r\n",
        "READ_WAV = 0 #1\r\n",
        "TRAIN_MODE = 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7UZPkZEjjyT"
      },
      "source": [
        "#### 2. load dataset & data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "pgw9guvxjoBi",
        "outputId": "d5e71947-c453-46cf-939c-602e90f41480"
      },
      "source": [
        "# 5가지 음성 라벨\r\n",
        "labels = ['go', 'happy', 'seven', 'stop', 'yes']\r\n",
        "\r\n",
        "# sample autio file\r\n",
        "# y: sampling data, sr: sampling rate\r\n",
        "y, sr = librosa.load('/content/drive/MyDrive/dataset/test.wav')\r\n",
        "print(y, len(y), sr) # 22.05 kHz\r\n",
        "librosa.display.waveplot(y, sr=sr)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.00045734  0.00092356  0.00115384 ...  0.00073417 -0.00068279\n",
            " -0.0008395 ] 22050 22050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PolyCollection at 0x7f1458ddda20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5b0/8M93spEEAgTCDoZNBUQWI8VWWxdUlBZbN7TtVXtdfl28S9vbW1qV2qotrV3sYlutdrO7tb+WFpW2lipYRIOICohsAcIWdhKyJ9/7x2zPJOdMzsycmXOS83m/Xr4425x5Mibf88yzfB9RVRARUd8X8roARESUGwz4REQBwYBPRBQQDPhERAHBgE9EFBD5XhfAztChQ7WystLrYhAR9Srr1q07rKoVVud8G/ArKytRXV3tdTGIiHoVEdlld45NOkREAcGAT0QUEAz4REQBwYBPRBQQDPhERAHBgE9EFBAM+EREAcGAT0QUEK4EfBGZLyJbRGSbiCxOct01IqIiUuXG+xLlwlUPv4j65javi0GUsYwDvojkAXgYwBUApgK4UUSmWlw3AMB/AVib6XsS5dKGPcex93iT18UgypgbNfw5ALap6g5VbQXwGwBXWVx3H4CvAmh24T2JiChFbgT80QD2GPu1kWMxIjIbwFhVXZ7sRiJyh4hUi0j1oUOHXCgaERFFZb3TVkRCAL4J4NM9Xauqj6pqlapWVVRYJnsjIqI0uRHw9wIYa+yPiRyLGgDgLAD/FJEaAHMBLGPHLRFRbrkR8F8BMFlExotIIYAbACyLnlTVE6o6VFUrVbUSwEsAFqoqcx9Tr9Pa3onW9k6vi0GUlowDvqq2A7gTwAoAmwH8TlU3isiXRGRhpvcn8pPrH1mDq7//otfFIEqLKwugqOrTAJ7ucmyJzbUXuvGeRLmkGv53Q+3x2DZRb8OZtkREAcGAT+RAtFZvV7vfvP8kdh9pBAC0d3Siua0jRyUjco4Bn8iBQw0tSc9f8e1V+NDjLwEAvrBsI6YseTYXxSJKCQM+kQN3/LznQWWdkcE7Ww82sJ2ffIkBn8iBFgdDMZlvh/yOAZ8oTY2t7ejs7F6Vf7nmqAelIeoZAz5RmqYuWYEvLNsY2x9UUuBhaYh6xoBPlIEnXtoV32G7PfkcAz4RUUAw4BMRBQQDPpFLjjd1XwbxeGMr/rxhnwelIeqOAZ/IwlsHTmL/ifSGWU4ZWRbb/smLNfiPX693q1hEGWHAJ7Iw/6FVuPYHa9J6rRqzrr7zj61uFYkoYwz4RDbcmEjFGbfkJwz4RC4Tkdj2/GkjPCwJUSIGfKIsmlBR6nURiGIY8ImyyGzRaWrtQOXi5Z6VhYgBnwJt3/EmNLa2u3pPsTnOtXDJawz4FGjvXPoP/M+TG1y9p1mrtwv+RF5gwKfAqz2WvbTGwohPPsKAT4Hn9tBJSdgW6xNEHmDAp8BTprmkgGDAp8DrdLkv1WzGsWrSUc7GIo8w4FPg5Tr8Mt6TVxjwKfCyWeNOqOBrwj9EOceAT4GX6xq3V0069c1tmLbkWU/em/yBAZ8Cb8vB+uzdPNKIf+xUa6xz2Ksa/tFTrTjV2uHRu5MfMOATJfHq7mOWx//yurNFTaJNOh96bG3sWC4r+C9uO8x0DhTDgE+UxJrtRyyP/23TwZTuc+RUSyzQ53IY6K4jjbbnGlrcTSlB/seAT5REOu3tVkMxzQlYfhmlc9YXVmDTvpNeF4NyiAGfyKGWdmft33uOxlM1RIO/HyZ3WT1ojje15r4g5BkGfCKHfvnSbkfXnbBYzById9bmsoafTi6fH72wA9O/sML9wpDnGPCJkjCDc0dn+pFaPEqk0+PDxeL8q7uPoZ7t+30SAz5RGpzW0hPb7qPDMnPfvLPPhfV5qfdjwCdKIiG3vUuVdC86bec/9AI6LN64tSOcSKihpR31zdZNUdR3MOATJWEXnJ0G/+h1rR2d8Tb8jEuVuoaWdqx6+1C348teC88nuPYH/8L8h1YBYA7/vizf6wIQ+VmHTSpN80GQbMWsaOw8esqb0TBvHYgPu7R60LxccxQAsOPwKS7BGACs4RMlYfbT2tX2n7eoOSeTy1w6T1bXxratKu7R1b5YqQ8GBnyiJDodBGcnwfL04f1jD4zN+7OYu6cLpx3ECTn8Gf77LFcCvojMF5EtIrJNRBZbnP+UiGwSkddF5DkROc2N9yXys2118cBuBtHrH1mTszJEHzIikjT0M8gHQ8YBX0TyADwM4AoAUwHcKCJTu1y2HkCVqp4N4PcAvpbp+xLlgpP6sVk7rj0Wz13zy7W7UVffErvGi+GYsZm+qhgzuMT2uhDjfSC4UcOfA2Cbqu5Q1VYAvwFwlXmBqq5U1ehfwksAxrjwvkQ5ZTd6xWz1OXiyObYdEsHJyFBHr/LnmDX3EWX97K+z+eG21TUw22Yf4kbAHw1gj7FfGzlm51YAz1idEJE7RKRaRKoPHUqtI4wo25wE7ZAROAvy4n9eze0d3b4u3PT4Wmw/1OBW8Sxde064bmUX0M8aXRY5b/36nYdPZaVc5I2cdtqKyIcBVAF40Oq8qj6qqlWqWlVRUZHLohFZMoO8k/HpZsAPSbxD1+qlL2w9jJVv1WVUPit7jjbiiZd2AQDGDC4GYD8yKPpQsvvRuh6vXLwcTVxEpddyI+DvBTDW2B8TOZZAROYBuAvAQlVtceF9iXLKSQ1/5ZbEAB6tWStyN+Hq8dU7cc8f34y8f2I5gMTg39CcPGeO1UOuqY0Bv7dyI+C/AmCyiIwXkUIANwBYZl4gIrMAPIJwsHe/SkPkEw/9fWts+/v/3O5JGey+iUSPX/C1lbFj0YRw5gOh3ZhsZnUvr9bkpcxlHPBVtR3AnQBWANgM4HequlFEviQiCyOXPQigP4AnReQ1EVlmczsi37ILpMnG6u+ItNELrL8hZCN29nTP6GQrwEzZHH9RewcDel/lSmoFVX0awNNdji0xtue58T5EuWYOpbQLpIcb7NMmbKg9YXmvKCcTuzIRHaXTU/eD2m1bPaQi/7a2d6Iwn3M3exP+3yJC4iQpOz9/qSb7BXGBuQBLOonQ7JpsYumdI6dPv/uZrHQ6U/Yw4BMBWLZhPwBgd5dFv81x7ObShakSEcvacgZrqtgyh3r2NKImOuzS7ouGeTxaVvOBYE40I/9jwCeKuPSbz+PdD65MOObW7FjV3M2znTIiPLZ+/e5jaIvku++ppt/eEe+otW/e0aTnyf8Y8IkAQBVb68I140yWMkz+FrkNj5/87WuYOKx/bD9Z0G+2SY1sltmLNXnJXQz4RACONsY7Xp10pKYa8xTWgTKbnbZd75yXYcKcaFHNMkc3f/LizoTc++RPDPhEAFZtPRzbdhKD/TzbNJ4wLb3Xm68zb9Fp1aQTOfbFP2/CDzyad0DOMeATIbEZx0lrezqV5Z++uDP1F6UhPrs2PqHKrtM44XWRf3v66a2aecLHUyomeYABn6gLzVKv5OMv1rh3s6S6j71PtzEncZSOdjuWcG3k3437TuDtg7lb5IWcY8Angn0Qa7fpwE31ObDriPXwxc4sdBBnvAi5zRMvPizT+tJozX/Bd1bjmh/8K8NCUDYw4BPBvkPz8dXWzTDNPksg9swb+7Hwe6sBWNfsW1JYoDyx3T6+HW32ctLkla2RTpQZBnwiAB+YFV/CwUlbtNnJm45v/HVL+L0yukvcyi11eD2SxiFhfVpj2+7nSjbLuM0cn2/RpGM1Ygfgouh+xYBPhNyPkf/uP7ZF3ted+7UaNfjqmmOxbSf3n/fNFxL2zSBu1tSjm3ZDSdWi+Yf8hQGfAstutEnNkdyt8pSN+bdTR5VF7p1qWRI3dhxqQL2RL99qWKaZVtnIqhy79uipVmzYczzFklC2uJItk6g32lYXzzljNkE8uGJLzsqQjS8W0cXKBal14HYdlnnxN55POB8N4nYdzWbNP9pncP9fNuEP6/eiZukC5wWhrGENnwKrwybabtrX+2aMmjVtJzH+X9vs+yDsHkLRGnx7p8aakMxvSVbPgZYO553FlH0M+BRYdjNKD5xszlkZ3EqtkDAyxybim81HH3xsrcV54OWdR7Fmx5Fu5/Yeb8K/tocfEk+tq8Xpdz8DILH8Vj9LgTH6qe5kM677IYdreolNOhRYduPJc8m14YsWQV66RP4F31nd422++4+tlscXP/V6bGRSdIH0rhpbu6+PW1yYF9t+vfYEXjE6lCn3WMOnwKqrb7bcziW7ZiUn1u8+hqffCOfxF5cGQtoNN11tNAFNHh7PwHngRAsqFy8HYP3QLMqPB/z8vHAZszHZjJxhwKfAenNvfPnB31XXelKGTL5ZfPrJDfj4L18FALS0xyeCmcF/dYbzBaLMcs4YMyi2fdB4UIoIKhcvx4CieMOBuQRiKPKNo5Xt+p5hwKfA8sN6rK3tnVj0yJq0XmtOilq782i387XHGvGbV/akXbZURZvrG1q6N+0AwP4T4RXD2jsVqorKxct9N2O5r/P+N57II39cv8/rIuBkUxvW7jyK9o7OhADuhFmTv/iMYW4XLcGogf1i2wlpKCz6QaKH3tx7ArXH4stCHjkVXnOgo0NjwzYPnPCmKS2oGPApsD40d5zXRcCru8OdmJPuegbXpphwzOzwHVRS4Gq5ujJXxDLfN2QE/+b2xNr6e7+7OtbHcM8f38Qv1oQ7e1s7OnEq8i3gUENL1spM3XGUDgXWgH7ZDZJOFBfG/wQ31Mb7FP7y+j4smD6y20gb097jxqLqkctqDp/CkVPhINrW4V7nqDnevt24b4cxvbYlSfOMObLnY79YF5v01u5iGalnDPgUWLnOn2PFbsTKnb9aj/OXDMWgksKU7nfh1//pQqm6O9bYFttuM4K8mcMn5HBab/Wu+NDMVJuxKDNs0iHy0JYkC4VEn0eVi5cnzWiZC8PLimLbZq281dhuS2O4ZSppmylzDPgUWD6o4FtSiyRlB05429Z9xvCy2HZ7Qg0/3ozTaDM6J5nG1vbYiJ11uzgpK9sY8Cmw7GaVei022iUhm2d4+829J7DnaHj1rDmV5bHzbk28stPaEQ/sZt/A5v3xbx7p1NbvX74Z4z/3NACkPTyVnGPAp8Dafih3aZCd2lbXEMtJY87CbWoNB9z3fnc1rnr4RQDxmasr3zqILQeym/DNbKtvN9rdBxbHO76b0hhTf6g+/s1l4cxRaZaOnGKnLZGPzPvm8/jatWeHd4w2nT3GePbRg4qxauuh2P5Hflqd9XK9ujue096syZszfNOp4RfkSewbw8SK/j1cTZliDZ8C6cZHX/K6CLb+uvEggMQ2fLPTdMehBvzb4y/nuFRxZmBvtdl2ymweqm9uS3IluYEBnzzz8MptscRbuaSqlimA/eLvmyMBP2Ht2Pj2qVZv0xGYtXpzuGamojNxN+w5jh2HGnq4mtLBJh3yTHRlqdb2Tvznr9fjux+chYbmdgwuTW3seaqs8s74kZm//mRTG55YU5Nw/mSTNzXiN/fa9xeEJP31bH9fXYsnjSR2XCXLfQz45IqOyCpIZv5zk6riUH0LhpX1Q0t7B7bXxTtM//BqLZ7deACT7wovqrHxi5ejtCh7v5rpND144Zk3DsRG5Dy+eid2Hk7sZH7T5ytz5YcE7SlEf5+Oku1TGPDJFd/629v43sptlrWyNduP4MYfhdvM/3zn+Xjf9xIX4lj8hzcS9ncdaYwtxN2TlVvqsOdoI246r9JxWY81tjq+1ktf+sum2HbXYN8bZBrAVTVpaglKHdvwyRXfW7kNADD93hWJOV6AWLAH0C3YW7nyO6sS9isXL8dPX9yJl3cexWOrdiSc+8hPXsGSP21Ee0cn9h1vcrSQCUeDZI9Zoc80dcU7vvwcfvj8dmyra2AKBpewhk+uqm9ux7uW/iNW00+3U7a1vRP/2n4YF0bS/t7753ht99bzx3er+U2KNAcBPbf9Mgd7bmQ6k7muvgVLn3kLS595CwDwrUUzMHvcYJSXFvoi8V1vxIBPWdHRqYl501MUXSR73d3zup277pE1OK28FN+4fkZa9772h5zRmQtmvBc4a+JJ1un7yd9uiG2zQzc9DPiUMXOpwKgpS551pXP0nPv/3u1Ydc0xVNccw9wJ5RavAH6/bg8uPGMYhvYvsjxP/uW0j/df2w9jSGkRnnq1Fp+/ckp2C9WHiB9SxFqpqqrS6urszyCkzJxsbsPZ9/7V62J0kx8SbPvyld2Or91xBIt8POmKUsfafiIRWaeqVVbnXOm0FZH5IrJFRLaJyGKL80Ui8tvI+bUiUunG+1JutXd0xjriWto78Oyb+30Z7IHwuqkb9yV+8/jIT15msO+DKhcvx9n3rvC6GL1CxjV8EckD8DaASwHUAngFwI2qusm45uMAzlbVj4rIDQA+oKqLkt23aw1fVbFp/0lMGzUwdqylvQMCQUNLO2bf9zfcdv54FOaHUF1zDHctmIJpo8qw/PX9KCoIoSg/D2MGF2PckBIU5edhw57jyAsJQiIQAc4cMQAigua2DhTmhfC/T72O+uY2fHb+mairb8HcCUMAhKd/d2pi0qhsaGnvQFF+4pj2TIaptbR34PJvvYCaI43YsOQy/HXTAZxoasPm/fWxtvDo/Ts7Fc3tHSiJrMb08s6jmDO+3JNZsW4YVFKA4y7OCCX/euADZ+H9M0fHFqhv6+jEqZYODC4pwJPrajFz7CDU1bfgrf0nERLg9ndP9LjE3Z1qaUdJYV7sbz0ao6P7PfWPJavhuxHwzwNwr6peHtn/XKSQXzGuWRG5Zo2I5AM4AKBCk7z58AlTtfj6BzMqGxFR0Oz/2X+jZf9WyyeCG006owHsMfZrI8csr1HVdgAnAAzpeiMRuUNEqkWk+siRwy4UjYiIonw18UpVH1XVKlWtKh4w2OviEBH1KW4My9wLYKyxPyZyzOqa2kiTzkAASdMVnjFiANY8cEU4R0tHJ0oL8/GjVTvw0fdMxJGGFpSXFqL2WBP2HW9CcWEeFn7vRYwfWoqCPMHbBxvw7RtmYt6U4XhwxRaoKuqb2zFxWH98+B2nYWBJAZ5YU4Ojp1px4GQLJg/rjwsmD8Xk4QOw8/AplJcWYtEja/DWgXr88MPnYOO+E/jERZPQryAPWw7Uo62jExMr+ifkjensVIiEJ5uEbNrXjje2Ol6Uet2uo5g5djDaOjrRryD8PvXNbSjIC8X2ow43tKC4IA8KoL9NDpo9RxtxwddWAgCe/8yFuPNX61Hf3IaaI42xUQ6H6lswtH8hWjs6sf94M8aWl6C5rQNffnoz7rvqLEz4/NOOyk7klVveWYlbzx+Pk81tKMwLobmtEyeb2zBlZBnmP/QCpowsw8GTzTjc0IIZYwbh4Q/NRmFeCKFQuC/Q7u+nq6OnWlHeQ5K/6AL1IrDte7Pql1v5Vh2mjSpDxYDwsOJTrR0QIJZfav+JJowcWAxVjS06E+1vAwD56nvX2ZXJjTb8fIQ7bS9BOLC/AuCDqrrRuOYTAKYbnbZXq+r1ye6b6rDMhpZ2lESCXkenxjpt0hX9n2UXvIPo4MlmDCktRH5eCDWHT+GeP72JVVv92/T2rUUzcPm0EbE/ht7a6UzObP7SfNvkfUGS1U7byBtcCeAhAHkAfqyqD4jIlwBUq+oyEekH4AkAswAcBXCDqu6wvyPH4fcWh+pbcO4D3SdH+YHV+OzfvrIbn33qDYurqbeqWbqAidYMWR+Hr6pPq+rpqjpRVR+IHFuiqssi282qep2qTlLVOT0Fe+o9KgYU4eEPzvbkva89Z4zl8Wtmj8aK/3635blF547LZpHIhtuheMl7p+LuBfEZtgz2zviq05Z6pyunj+h2bMv98/HWffMzvvdTHzvP8vjEilI8GF37tYuvXzcDZ4wYkPF7U+45bUH99/PH47YLJnCWbYqYS4cyZlW76jppLFXVd8/Dj1fvxDmndc+Xs/WBK5AfEttaXU+1vfvefxbu+eObGZWPeuY0YZopWS6dGWMG4r/mTUZeiPXUdDHgk+t+ffvc2HbN0gVpdZYO7V+E/51/Zmz/pvNOw8SK/vjD+r0oyOv+B7/285dg/4lmFDnorD9nHIf85oQR8dPtKRwzuBifv3IK5k4Y0uOoGOoZAz654oPvGIdfrd1t+RX7c1ecia9EcprfvWAK7l++Oem9Hr85sb9pw5LLMKBfPkIhwc3vrEw495nLz8CGPccxvKwfhpf1c1TWrXX1jq6j1Jm1+pAIOjIYFPLakksdD2MmZxjwyRX3LJiKj19onZfk/71nIm44dxzW7DiC+WeNwOXTRmBbXQM+8tNXAABfXDgNX1gWG8WLqsrEZpyBJfZ5iz5x0aSUyzq4lwSReVOGY8uBk9hzrCmjxcFzKSRAR6ScmXajMti7j41h5IriwjyMGVxie35gSQHmnxXu3B1bXoKLzhwWO/e+GaMAhBc7WXr19Kwnpust7nv/NKz67MUAgMVXnIkb54xNOD92cLEXxUrKfCalsoA55QYDPnnmsqnDAQDlpYWoWboAQ/oX4YY52R82ed7EbmmcfEmMOvLwsn74ytWJo5LGlts/YLPpzCQjoDKJ8dfMHo1X7pqHuxdM6dasR+5gkw555vsfmo2Glvacv29BXgiDigtwvMmfKZMvmDwUq7YehjnYKOSjceYlxmxWN1NPl5cWomJAEW67YIIr96PuWMMnz+TnhTxrp622WCvXL+ZE+jDMEG8+nKaOLMOnLzs9x6WKM4fcFhojpgryUn8o5RsD79mUl30M+BRI+RZDO/3gx7dU4WPRzm8jfprB8MDJZvzHxZNj+/9z2emYWFGa1XLNHjcotm3mqSoqMLbTmHthtvMf4yI1WefP33qigLr4zOGx5ps8oxmnPPJN6KvXTI+lsoiOeLzz4sm4dGr32c5uKsi3rsmbzTn9CjILJ4+v3pnR66lnDPgUWA8tmul1ESxF47zVjOFF546LdTqv2RHPMK5pT21yJrHpJr49ZURZbDudGv63Fs3Ai4vDI5F++GFvcjIFCTttKbB81A+aIBrozeKVFXv7p1pX3xLbNpvDzCadkjRSE5cU5mP0oGK8dd/8bus8kPsY8Ik8VFqYh1OtHZbnog+kdXfPw5D+RUnvI67no0y05UB8dnKB0dFq1vydpLXoKhrkGexzg006FFh+SKk7abj1mParZ42Orb7UU7AH4k06j99chXdmYZ6B2VGbb7Thm8c7Hd5r1KB4Cox0RvZQ+hjwKbDa2p2GqOypO9kc2x5eFg/s31w0s8eRRNEl8EyXTBmOd4x3P+CbS/+Z5TK3C5OU16z9//r2ufjHp98DILFjmrKPAZ8C65drd3ldBLxjfHjM/WtLLrVdtMVOsdEM0mrx8HKz9mzmqTfHzncaydG6tuF/9ZrpqDotnJl0y/1XYMl7pwIABhUXYuTAcFoIJ99eyD0M+BRYXZO0eWFAv/D4+kElhSlPQjNH5jzzxoHu510cuNNiPFA6zPwJSd5j0bnjMMsYvx99OIRC8Rr/iIHOMpySOxjwKbBG+iDYFBfmpb1qU76xEMjUUWXdzo8aVOzahKz6ZpsUGEbNP/qAMb95mP0kk4b1BxAe1hkKCbbcPz+hqYiyjwGfAstsA583ZViSK7MnkybsT156eiwltZnyOVrzzwsJPnmp+ykYdh4+FdseZMwAVii23D8/4Wdq64h/M4g+oKLj+DNdFY1Sx4BPgTVhaP/Y9pkjuteQcyGTTsuFM0bFVgVza+LVjLGDLI9fMHlobNuc8HXakBLs/MqVsf2i/Dw0GsNMzaagxtbwt4Q8pwvXkusY8Ing3SQs17JgOoj3y//z/B6v+fd3VVoe/69LJmPB9JEAgA/MHJ1wLtpsYzWWvskI/pNthqBS7jDgU2CZsdarOmfIpdquGe+ddNYuvXp6t2MC4KqZo3HehO7DOqsqy3FPZJTNR941Hms+F06HYD6wrNYabjWadMYPLU27v4LcwYBPgWUGKzNGXnRGRc7K4NaDRo0orxbHwu8Vf7dkC83YfemIPpv6FYRiwyrNTlnLl3HRK19hwKfAqhwaXzHKjI03dVkoPZuy0ZR0orEVQDjWpjM0M1qkX942B5+5/IzY8ei3EbtvJVbNU5+67HTfJqkLIo6JosAyR4mYsWpuFmaq2slGDpxVWw9H7p2myAvfNakCB0/Gk6aFLJK6md8ijFGisaGZEyv6Y2JFf5A/sIZPBOv252yK5rtxq4afZ0TbOePjE8qc3P/RfzsnYd98CIUsmmzsOpqzncCNMseATwTg6Tf2x7adBMmZNsMXnfrV7XPD75XRXeJmjB0Y2zaHPTpp0rlsWuLiKWaLjfkgjDbl2K21m9AJztjvSwz4RIDtYurXnTPG8rhV4jIv3XReJbY9cAUA637SovxQWkHY/OITfZA4qcn7adF1imMbPlES5aXW+W1SDWenDSnBriON3Y67NSwTiGeuVGepbuwlBGuzeaf76cTt8M63b5iJkkKGFj/i/xUiJGmCcLGiesaIAQkLiWRP9zCf7ujIxLkK3Zt0Eq6N/HtVl4lZ5B9s0iGCfVu0nc40xjs+dlNVyq9JR7RoCUktHZQ3eoV1/d56rV2r8+RfDPhEAGYZnbBO2qiLfdxkEY3tIomBPtOAHAv4CcfCe1fNHIUPzGLN3u/8+1tLlEPjyuOTsJwk90o1doZELANuNjs3u9650+ECX/YzbSXhX/Pab98wK8XSkRdYwycCEqJcNrI5qmrO19D95KWno/ZYU2w/nWYoq+YbNt30Xgz4RBHbv3wlnrh1TsIxNycTWd0pG8Fz19FwvvqrZo5OyEefjN1CJFbNN3Zt/OR/DPhEAM6fNBR5IcEFk7OXOM0quGcjYEaXTQTigdyucj9+aPcVsXoasGTW+suMBVDI/xjwiZCYjsDOXVdOyUFJMjd6UHFs22krjpNvGvFROuF/V3/2Irzv7FEplo68xIBP5JBdUByQZF3WfgXxPzGr5qFctocnC/5mMezTJSQ26YwZXOLqxDHKvowCvoiUi8jfRGRr5N/BFtfMFJE1IrJRRF4XkUWZvCeRV+wCZnGh/dqs8yN5auxibTYSjplBuqelD63enUG878q0hr8YwHOqOhnAc5H9rhoB3KSq0wDMB/CQiGSWeYooR9QmdycAAAuGSURBVOxq4HZh9LKpw2Pbt50/PnGUi1Ubfo5iq1neDUsuMwrQ/XxBXvLka7kebUTuyTTgXwXgZ5HtnwF4f9cLVPVtVd0a2d4HoA5A7pYUIsqAGfCcLIn4iYsmxbYL80OxiU+S5DVue9+M+CQoq4A9sCTe0TowjU5X84FAvUumE6+Gq2o0r+wBAMOTXSwicwAUAthuc/4OAHcAwLhx9kuwEeVKQvOITbXePGyOde/U5DlsivJDmDWuWytoxmaPG4zZkfueimQBtUutEJuVaxwzm5m6jt3f+MXLUZqkz4L8rcf/cyLydwAjLE7dZe6oqoqI7e+3iIwE8ASAm1XVcnCwqj4K4FEAqKqq4mqY5DknuWLMw2aAbDfGwBfmh7pV8bfcf0XmBezBY6t3ArBvhnltz3EAiXl3TCMG9kvYZ7Dv3Xr8v6eq8+zOichBERmpqvsjAb3O5royAMsB3KWqL6VdWiIP2dXwzVg6sDieTrlDFSWRDl2v8sObD6DjTa2219l9Azh7zKBYnn3q/TJtw18G4ObI9s0A/tT1AhEpBPD/AfxcVX+f4fsR+Y4ZKycNi6/fetnUERg1sDh2jRdLAJpl21bXYHudXQ0fiOfZp94v0/+TSwFcKiJbAcyL7ENEqkTkscg11wN4N4BbROS1yH9cxp56nVSX8DtvYnwxdHN45NKrp7tZLEdUNenjpqfhm9Q3ZNQgp6pHAFxicbwawG2R7V8A+EUm70PkFbMpJmElqRRXlXr7YLx2veDskS6UzJmE8ie5LvHnYfDvq/hdjSgJJ3OQJhvNOMlYLSCSbRedGR8BbdVMX5QfWRYxVwUiTzHgEyVhN+vUjNk/vuVc29dHA2lxgf1s3Gw6f5IR8C3OX3TGMABAWb/82Pj6NLIoUy/BMVZESdiNrjGDYr8kwTx63cDigni2SZfKlqq5E7oniPvA7PAErWV3np9WvnzqXRjwiZLIRnD2YoTmUx97J0otlmUc0C98bJSRYZP6LjbpECVhl4jMadBOfE0022TuI342ZvRS78OAT+SQ3SgdR6/1a7eoRbHGGuv7Ut/CgE/k0HVVY2PbyWr4hfnJ/6z8nmzyM5efgdfvvaznC6nXYcAnSsKsyZeXFtpfaDh9eHyYZkK2TbcKlSarB02RRYdzQV4IZf24dGFfxE5boiSyURvPZQ0/2Xv9/VPvxsQKZ3MIqG9gDZ8oiSkjyyyPTx890PY1Vu37IZH4xKsc1vUHJcl3P2nYAC5mEjAM+ERJXDLFeomH2y6Y4Oj10dj/69vnxo7lMsbOP2sEXr6rW/YTCigGfAq8CRWl2bt5pLpfObQ0VrPPZZ1aRDBsQDin/QC2ywceAz4FXmGO0/961YxSXlqImqULPHlv8gcGfKJckYR/iHKOAZ8CL5urUVlNt2I/KXmFAZ8Cz+0A3NOMXI6MIa8w4FPgebXeLFGuMeBT4GUz3vs2hw4FEgM+BV5JYfYWJ0lo0mHsJ48xtQIF2rI734WRA5kLnoKBAZ8C7ewxg1y/p11FPi+PfQXkLTbpEOVI/6J8rL/nUq+LQQHGgE+URSea2hL2BztMsUyUDQz4RC5To6f2l2t3e1gSokQM+EQ2SrM4eofICwz4RBa+98FZ+Pmt70jrteZM2o++Z6JbRSLKGEfpEFl479mj0n7t5v0nY9uLzh2Lhpa2JFcT5Q5r+EQusVpdavzQUtz//ukelIaoOwZ8IqKAYMAnIgoIBnyiFHRNtDZ3QrlxMrdlIUoVO22JUmAmQ1v1vxehYkBRbP94Iztnyd9YwydK09jyEvQr6D5Wf05lucXVRN5jwCdyyaiB/bwuAlFSDPhEDjx47dk9XhOdcDWkP/PlkD+xDZ/IgWmjBiY9/50bZ2FIJDHag9fNwJL3Tc1FsYhSwoBP5EB0dI6I9cLkC2fEZ+b2L8pH/yL+aZH/sEmHiCggWA0hciBawx9Z1g+tHZ3eFoYoTRkFfBEpB/BbAJUAagBcr6rHbK4tA7AJwB9V9c5M3pfIK3/5zwsS8t0T9SaZNuksBvCcqk4G8Fxk3859AF7I8P2IPFVeWogh/Yt6vpDIhzIN+FcB+Flk+2cA3m91kYicA2A4gL9m+H5ERJSmTAP+cFXdH9k+gHBQTyAiIQDfAPA/Pd1MRO4QkWoRqT506FCGRSMiIlOPbfgi8ncAIyxO3WXuqKqKiFXj5scBPK2qtdI181QXqvoogEcBoKqqig2lREQu6jHgq+o8u3MiclBERqrqfhEZCaDO4rLzAFwgIh8H0B9AoYg0qGqy9n4iInJZpsMylwG4GcDSyL9/6nqBqn4oui0itwCoYrCn3qaCHbXUB2Tahr8UwKUishXAvMg+RKRKRB7LtHBEflCzdAFH5lCfIH4dU1xVVaXV1dVeF4OIqFcRkXWqWmV1jqkViIgCggGfiCggGPCJiAKCAZ+IKCAY8ImIAoIBn4goIBjwiYgCwrfj8EWkHsAWr8vhE0MBHPa6ED7BzyKOn0UcP4u401S1wuqEn1e82mI3eSBoRKSan0UYP4s4fhZx/CycYZMOEVFAMOATEQWEnwP+o14XwEf4WcTxs4jjZxHHz8IB33baEhGRu/xcwyciIhcx4BMRBYQvA76IzBeRLSKyTUQCszpWTz+3iHxKRDaJyOsi8pyInOZFOXPB6e+AiFwjIioifXZInpPPQkSuj/xubBSRX+W6jLni4G9knIisFJH1kb+TK70op2+pqq/+A5AHYDuACQAKAWwAMNXrcvnh5wZwEYCSyPbHAPzW63J7+TsAYACAFwC8hPDSmZ6X3aPfi8kA1gMYHNkf5nW5PfwsHgXwscj2VAA1XpfbT//5sYY/B8A2Vd2hqq0AfgPgKo/LlAs9/tyqulJVGyO7LwEYk+My5orT34H7AHwVQHMuC5djTj6L2wE8rKrHAEBV63Jcxlxx8lkogLLI9kAA+3JYPt/zY8AfDWCPsV8bOdbXpfpz3wrgmayWyDs9fhYiMhvAWFVdnsuCecDJ78XpAE4XkRdF5CURmZ+z0uWWk8/iXgAfFpFaAE8D+I/cFK138HNqBbIhIh8GUAXgPV6XxQsiEgLwTQC3eFwUv8hHuFnnQoS/9b0gItNV9binpfLGjQB+qqrfEJHzADwhImepaqfXBfMDP9bw9wIYa+yPiRzr6xz93CIyD8BdABaqakuOypZrPX0WAwCcBeCfIlIDYC6AZX2049bJ70UtgGWq2qaqOwG8jfADoK9x8lncCuB3AKCqawD0QzixGsGfAf8VAJNFZLyIFAK4AcAyj8uUCz3+3CIyC8AjCAf7vtpOC/TwWajqCVUdqqqVqlqJcH/GQlWt9qa4WeXk7+GPCNfuISJDEW7i2ZHLQuaIk89iN4BLAEBEpiAc8A/ltJQ+5ruAr6rtAO4EsALAZgC/U9WN3pYq++x+bhH5kogsjFz2IID+AJ4UkddEpE8+CB1+FoHg8LNYAeCIiGwCsBLAZ1T1iDclzh6Hn8WnAdwuIhsA/BrALRoZskNMrUBEFBi+q+ETEVF2MOATEQUEAz4RUUAw4BMRBQQDPhFRQDDgEwEQkSGRoa6vicgBEdkb2W4Qke97XT4iN3BYJlEXInIvgAZV/brXZSFyE2v4REmIyIUi8pfI9r0i8jMRWSUiu0TkahH5moi8ISLPikhB5LpzROR5EVknIitEZKS3PwVRGAM+UWomArgYwEIAvwCwUlWnA2gCsCAS9L8L4FpVPQfAjwE84FVhiUzMlkmUmmdUtU1E3kB4QY5nI8ffAFAJ4AyEE7v9TUQQuWa/B+Uk6oYBnyg1LQCgqp0i0mbkaelE+O9JAGxU1fO8KiCRHTbpELlrC4CKSC52iEiBiEzzuExEABjwiVwVWXrvWgBfjWRsfA3AO70tFVEYh2USEQUEa/hERAHBgE9EFBAM+EREAcGAT0QUEAz4REQBwYBPRBQQDPhERAHxf61Zz0YRq3zBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5qYW5XFjoVR"
      },
      "source": [
        "# 오디오 파일 읽고 처리\r\n",
        "def read_wave():\r\n",
        "  begin = time()\r\n",
        "  print(\"Resampling start...\")\r\n",
        "  # 자연어 처리(기사 카테고리 분류)에서는 pad_sequences를 사용했었음\r\n",
        "  # 이는 뒤나 앞을 0으로 채우기 때문에 이는 안좋은 방법!\r\n",
        "  all_wave = []\r\n",
        "  all_label = []\r\n",
        "\r\n",
        "  # tqdm 함수는 진행 사항을 표시하기 위함\r\n",
        "  for label in tqdm(labels):\r\n",
        "    path = MY_PATH + '/' + label # 5가지 음성 라벨 폴더 경로\r\n",
        "    waves = [f for f in os.listdir(path)]\r\n",
        "\r\n",
        "    for wav in waves:\r\n",
        "      # 1개의 오디오 파일을 16kHz로 샘플링함 (기사 분류에서는 200개 기사 길이로 했었음)\r\n",
        "      # 1초당 16,000개의 숫자로 샘플링함\r\n",
        "      file = path + '/' + wav\r\n",
        "      samples, rate = librosa.load(file) #, sr=16000) # sampling rate\r\n",
        "      # orig_sr=22.05kHz -> target_sr=8kHz\r\n",
        "      # down-sampling (16kHz -> 8kHz)\r\n",
        "      samples = librosa.resample(samples, orig_sr=rate, target_sr=8000)\r\n",
        "      #print(\"샘플링 이후:\", len(samples))\r\n",
        "\r\n",
        "      # 어떤 sample은 8kHz가 아닐 수 있음 (8kHz보다 짧은 것도 리샘플링이 가능한가?)\r\n",
        "      if (len(samples) == 8000):\r\n",
        "        all_wave.append(samples)\r\n",
        "        all_label.append(label)\r\n",
        "\r\n",
        "  end = time()\r\n",
        "  print(\"Resampling finish...\")\r\n",
        "  print(\"Total sample num:\", len(all_wave))\r\n",
        "  print(\"Resampling time: {:.2f}\".format(end - begin))\r\n",
        "\r\n",
        "  return all_wave, all_label\r\n",
        "\r\n",
        "#read_wave() # 함수 정상 실행 여부 확인"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N67FXA8oAPo"
      },
      "source": [
        "# text label을 [0, 9], One-hot encoding 변환\r\n",
        "def set_arrays(all_wave, all_label):\r\n",
        "  encoder = LabelEncoder()\r\n",
        "  all_label = encoder.fit_transform(all_label)\r\n",
        "  #print(all_label)\r\n",
        "  all_label = to_categorical(all_label, num_classes=len(labels)) # all_label은 numpy 배열로 변환됨\r\n",
        "  #print(all_label)\r\n",
        "  #print(np.array(all_wave).shape) # (349(오디오 데이터 개수), 8000)\r\n",
        "\r\n",
        "  # 음성 데이터를 3차원으로 전환\r\n",
        "  # Keras Conv층을 사용하기 위한 조건\r\n",
        "  # 349, 8000, 1 대신에, -1(or np.array(all_wave).shape[0])을 앞에 넣어주는게 좋음\r\n",
        "  #     -1: 1차원 정보를 알아서 계산하라는 의미 (당연히 349를 보존할 것임)\r\n",
        "  all_wave = np.array(all_wave).reshape(-1, 8000, 1) # 3차원(배치->CNN채널정보 추가)으로 변경\r\n",
        "  #print(all_wave.shape)\r\n",
        "  return all_wave, all_label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evy4LL93oAhX"
      },
      "source": [
        "# 데이터 처리 모드 선택\r\n",
        "if READ_WAV:\r\n",
        "  all_wave, all_label = read_wave()\r\n",
        "  all_wave, all_label = set_arrays(all_wave, all_label)\r\n",
        "\r\n",
        "  # all_wave, all_label 처리가 오래 걸려 이를 파일로 저장해서 사용\r\n",
        "  with open('arrays.npy', 'wb') as f:\r\n",
        "    np.save(f, all_wave)\r\n",
        "    np.save(f, all_label)\r\n",
        "  \r\n",
        "  print('데이터 파일 완성!')\r\n",
        "  print('READ_WAV를 0으로 바꿔 진행하세요.')\r\n",
        "  exit() # 바꿔서 다시 실행하면 else로 넘어감\r\n",
        "else:\r\n",
        "  with open('arrays.npy', 'rb') as f:\r\n",
        "    all_wave = np.load(f)\r\n",
        "    all_label = np.load(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnq6FtRHRFov",
        "outputId": "2d8ce294-3a2f-4cb3-c73e-bdd6d31a8160"
      },
      "source": [
        "print('음성 데이터 모양:', all_wave.shape)\r\n",
        "print('라벨 데이터 모양:', all_label.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "음성 데이터 모양: (889, 8000, 1)\n",
            "라벨 데이터 모양: (889, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNUe_y0BRiHh",
        "outputId": "93b6cc5c-002f-478d-c091-9ad76c8b64f4"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = \\\r\n",
        "    train_test_split(all_wave, all_label, train_size=MY_SPLIT, shuffle=True)\r\n",
        "\r\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(711, 8000, 1) (711, 5) (178, 8000, 1) (178, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX8LGDIQgOCa"
      },
      "source": [
        "#### 3. model(CNN+RNN) creating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngoqp2CwRicq",
        "outputId": "89940cf0-4cc5-41d8-99b9-fd6ebe65d56c"
      },
      "source": [
        "inputs = Input(shape=(8000, 1))\r\n",
        "x = BatchNormalization()(inputs)\r\n",
        "\r\n",
        "# Conv output_shape = (input_shape - kernel_size + 2 * padding_size) / stride\r\n",
        "# padding='valid' -> padding을 주지 않음\r\n",
        "\r\n",
        "# Pool output_shape = (input_shape - pool_size + 1) / strides\r\n",
        "# stride=None(default -> pool_size)\r\n",
        "\r\n",
        "# First Conv\r\n",
        "x = Conv1D(filters=8, kernel_size=13, padding='valid', strides=1, activation='relu')(x)\r\n",
        "# 8000 - 13 + 2 * 0.5(?) / 1 = 7988 * 8\r\n",
        "x = MaxPooling1D(pool_size=3)(x)\r\n",
        "# 7988 - 3 + 1 / 3 = 2662 * 8\r\n",
        "x = Dropout(rate=MY_DROP)(x)\r\n",
        "\r\n",
        "# Second Conv\r\n",
        "x = Conv1D(filters=16, kernel_size=11, padding='valid', strides=1, activation='relu')(x)\r\n",
        "# 2662 - 11 + 2 * 0.5(?) / 1 = 2652 * 16\r\n",
        "x = MaxPooling1D(pool_size=3)(x)\r\n",
        "# 2652 - 3 + 1 / 3 = 883.3 = 884 * 16\r\n",
        "x = Dropout(rate=MY_DROP)(x)\r\n",
        "\r\n",
        "# Third Conv\r\n",
        "x = Conv1D(filters=32, kernel_size=9, padding='valid', strides=1, activation='relu')(x)\r\n",
        "# 884 - 9 + 2 * 0.5(?) / 1 = 876 * 32\r\n",
        "x = MaxPooling1D(pool_size=3)(x)\r\n",
        "# 876 - 3 + 1 / 3 = 291.3 = 292 * 32\r\n",
        "x = Dropout(rate=MY_DROP)(x)\r\n",
        "x = BatchNormalization()(x)\r\n",
        "\r\n",
        "# 소리(음성)은 시간 차원이(순서가) 존재함 -> RNN으로 해야 함\r\n",
        "\r\n",
        "# First GRU\r\n",
        "# RNN의 입력은 292개(unfold시 292개 cell처럼 보임)가 되고, 입력 차원은 32\r\n",
        "x = Bidirectional(GRU(units=MY_HIDDEN, return_sequences=True), merge_mode='sum')(x)\r\n",
        "# 차원이 32 -> 128(MY_HIDDEN)\r\n",
        "\r\n",
        "# Second GRU\r\n",
        "x = Bidirectional(GRU(units=MY_HIDDEN, return_sequences=True), merge_mode='sum')(x)\r\n",
        "\r\n",
        "# Third GRU\r\n",
        "x = Bidirectional(GRU(units=MY_HIDDEN, return_sequences=False), merge_mode='sum')(x)\r\n",
        "# 128개가 나옴! return_sequences=False\r\n",
        "\r\n",
        "# Output\r\n",
        "x = BatchNormalization()(x)\r\n",
        "x = Dense(units=256, activation='relu')(x)\r\n",
        "outputs = Dense(units=len(labels), activation='softmax')(x) # 5개 라벨 분류\r\n",
        "\r\n",
        "model = Model(inputs=inputs, outputs=outputs)\r\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 8000, 1)]         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8000, 1)           4         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 7988, 8)           112       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 2662, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2662, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 2652, 16)          1424      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 884, 16)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 884, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 876, 32)           4640      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 292, 32)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 292, 32)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 292, 32)           128       \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 292, 128)          124416    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 292, 128)          198144    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               198144    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 561,833\n",
            "Trainable params: 561,511\n",
            "Non-trainable params: 322\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThNx5HKYxeju",
        "outputId": "3c7dfddb-7b72-4d63-d1fb-4dbe2bc008f4"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['acc'])\r\n",
        "\r\n",
        "if TRAIN_MODE:\r\n",
        "  print('Learning start...')\r\n",
        "  begin = time()\r\n",
        "  model.fit(x=X_train, y=Y_train, epochs=MY_EPOCH, batch_size=MY_BATCH, verbose=1)\r\n",
        "  end = time()\r\n",
        "  print('Total learning time: {:.2f}sec'.format(end - begin))\r\n",
        "  model.save_weights('speech.h5') # 모델 저장\r\n",
        "else:\r\n",
        "  model.load_weights('speech.h5') # 모델 로드"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning start...\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 12s 141ms/step - loss: 1.7226 - acc: 0.2140\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 1.6721 - acc: 0.2213\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 1.6217 - acc: 0.2431\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 1.6489 - acc: 0.2424\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 1.5852 - acc: 0.2297\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 1.5590 - acc: 0.2438\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 1.5865 - acc: 0.2560\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 1.5314 - acc: 0.3076\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 1.5317 - acc: 0.3017\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 1.5333 - acc: 0.2973\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 1.5137 - acc: 0.2919\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 1.5087 - acc: 0.3302\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 1.4755 - acc: 0.3178\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 1.4971 - acc: 0.3058\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 1.4479 - acc: 0.3482\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 1.4301 - acc: 0.3709\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 1.4344 - acc: 0.3836\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 1.2921 - acc: 0.4552\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 1.0671 - acc: 0.5516\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 0.9353 - acc: 0.6106\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.9917 - acc: 0.5633\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.7617 - acc: 0.6996\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.6900 - acc: 0.7324\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.6668 - acc: 0.7276\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.5951 - acc: 0.7604\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.5252 - acc: 0.7934\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.4809 - acc: 0.8167\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.4031 - acc: 0.8562\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.3165 - acc: 0.8873\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.4338 - acc: 0.8395\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 0.2820 - acc: 0.8880\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.2229 - acc: 0.9412\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 0.2184 - acc: 0.9297\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.1673 - acc: 0.9503\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.1238 - acc: 0.9685\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.1208 - acc: 0.9685\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.1447 - acc: 0.9575\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.1551 - acc: 0.9513\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.1297 - acc: 0.9469\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.0902 - acc: 0.9712\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 0.0917 - acc: 0.9731\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0893 - acc: 0.9731\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.1297 - acc: 0.9444\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0642 - acc: 0.9889\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 0.0552 - acc: 0.9811\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0559 - acc: 0.9844\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0597 - acc: 0.9865\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0542 - acc: 0.9792\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.0379 - acc: 0.9904\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0730 - acc: 0.9801\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 0.0392 - acc: 0.9877\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0470 - acc: 0.9900\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.0305 - acc: 0.9922\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0406 - acc: 0.9848\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0305 - acc: 0.9903\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0318 - acc: 0.9934\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.3829 - acc: 0.8798\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.0562 - acc: 0.9898\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.0473 - acc: 0.9829\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0382 - acc: 0.9902\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0384 - acc: 0.9817\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0327 - acc: 0.9894\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 0.0231 - acc: 0.9972\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0220 - acc: 0.9920\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0177 - acc: 0.9968\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0304 - acc: 0.9929\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0237 - acc: 0.9936\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0172 - acc: 0.9956\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.0204 - acc: 0.9955\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0384 - acc: 0.9797\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0275 - acc: 0.9888\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0203 - acc: 0.9915\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0306 - acc: 0.9896\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0198 - acc: 0.9968\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.0599 - acc: 0.9887\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0170 - acc: 0.9951\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0269 - acc: 0.9945\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0129 - acc: 0.9996\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0526 - acc: 0.9755\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0265 - acc: 0.9906\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0169 - acc: 0.9941\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0110 - acc: 0.9960\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0202 - acc: 0.9944\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 0.0157 - acc: 0.9929\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0185 - acc: 0.9932\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.0155 - acc: 0.9982\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0238 - acc: 0.9965\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 0.0318 - acc: 0.9853\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 0.0224 - acc: 0.9970\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 1s 134ms/step - loss: 0.0368 - acc: 0.9796\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0346 - acc: 0.9864\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 1s 134ms/step - loss: 0.0361 - acc: 0.9883\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 0.0324 - acc: 0.9906\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 0.0137 - acc: 0.9936\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 1s 134ms/step - loss: 0.0294 - acc: 0.9884\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 0.0333 - acc: 0.9897\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0093 - acc: 0.9994\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0182 - acc: 0.9896\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 0.0097 - acc: 0.9970\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 0.0096 - acc: 0.9966\n",
            "Total learning time: 90.15sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQBZuhe5jnhJ"
      },
      "source": [
        "#### 4. model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpT2R3L4zEIL",
        "outputId": "dc1ff510-cdd3-4ebb-a311-81c64def3277"
      },
      "source": [
        "score = model.evaluate(x=X_test, y=Y_test, verbose=1)\r\n",
        "print('Total loss: {:.2f}'.format(score[0]))\r\n",
        "print('Accuarcy: {:.2f}'.format(score[1])) # 라벨이 5개 밖에 없음!"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 55ms/step - loss: 0.5217 - acc: 0.9213\n",
            "Total loss: 0.52\n",
            "Accuarcy: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j89TqDfs08Eq"
      },
      "source": [
        "#### 5. model prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5pyAKHm08Zs"
      },
      "source": [
        "# 주어진 음성으로 예측\r\n",
        "def audio_to_text(audio):\r\n",
        "  pred = model.predict(audio.reshape(1, 8000, 1)) # 채널 정보 없이 들어옴\r\n",
        "  index = np.argmax(pred[0]) # 확률 -> 가장 큰 확률의 인덱스\r\n",
        "  return labels[index]\r\n",
        "\r\n",
        "# 평가용 데이터에서 임의로 음성 추출\r\n",
        "pick = random.randint(0, len(X_test) - 1) # test 데이터 개수만큼 랜덤 정수\r\n",
        "sample = X_test[pick]\r\n",
        "truth = np.argmax(Y_test[pick])\r\n",
        "print('무작위 음성 정답:', labels[truth])\r\n",
        "\r\n",
        "audio, rate = librosa.load('/content/drive/MyDrive/dataset/SKL-yes.wav')\r\n",
        "print('Origin sampling rate:', rate)\r\n",
        "\r\n",
        "sample = librosa.resample(audio, orig_sr=rate, target_sr=8000)\r\n",
        "#print('Sampling ')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}